{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VROB1 TP Robin GAIGNOUX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"baboon.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "ret, I0 = cap.read() \n",
    "I0 = cv2.rotate(I0, cv2.ROTATE_90_CLOCKWISE)\n",
    "resize_factor = 3\n",
    "\n",
    "def copy_and_resize(I, resize_factor = resize_factor):\n",
    "    I_copy = np.copy(I)\n",
    "    I_resized = cv2.resize(I, (I.shape[1] // resize_factor, I.shape[0] // resize_factor))\n",
    "\n",
    "    return I_resized\n",
    "\n",
    "# Resize the frame for displaying purpose\n",
    "I0_resized = copy_and_resize(I0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ Pick points in clockwise order : topleft, topright, bottomright, bottomleft ⚠️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = []\n",
    "nb_pts = 4\n",
    "I0_copy = np.copy(I0_resized)\n",
    "\n",
    "def select_points(event, x, y, flags, param):\n",
    "    global pts\n",
    "    if event == cv2.EVENT_LBUTTONDOWN and len(pts) < nb_pts:\n",
    "        pts.append((x, y)) # column, row\n",
    "\n",
    "cv2.namedWindow(\"Image\")\n",
    "cv2.setMouseCallback(\"Image\", select_points)\n",
    "\n",
    "while True:\n",
    "    for pt in pts:\n",
    "        cv2.circle(I0_copy, pt, 2, (0, 0, 255), -1)\n",
    "    cv2.imshow(\"Image\", I0_copy)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if len(pts) == 4:\n",
    "        break\n",
    "\n",
    "    if key == 27:\n",
    "        print(\"Select 4 points !\")\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corners in I0 : [[ 138  264]\n",
      " [ 957  273]\n",
      " [ 930 1104]\n",
      " [ 144 1086]]\n"
     ]
    }
   ],
   "source": [
    "# Resize back to get the true values\n",
    "corners_I0 = np.array([(pt[0] * resize_factor, pt[1] * resize_factor) for pt in pts])\n",
    "print(\"Corners in I0 :\", corners_I0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrinsic Matrix :\n",
      " [[1.32770382e+03 0.00000000e+00 5.32455196e+02]\n",
      " [0.00000000e+00 1.32641206e+03 9.58009260e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "Distortion coeffs :\n",
      " [[ 2.06305258e-01 -1.53101813e+00  8.99855256e-04 -1.68850720e-03\n",
      "   3.94998963e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Chessboard pattern size\n",
    "pattern_size = (9, 6)\n",
    "square_size = 1\n",
    "\n",
    "# Chessboard points in object coordinate system\n",
    "object_points = np.zeros((np.prod(pattern_size), 3), dtype=np.float32)\n",
    "object_points[:, :2] = np.indices(pattern_size).T.reshape(-1, 2)\n",
    "\n",
    "# Lists to store object points (3D points) and image points (2D projections)\n",
    "# The points are matched: the 2D point at index i corresponds to the projection of the 3D point at index i\n",
    "obj_points = []\n",
    "img_points = []\n",
    " \n",
    "images = glob.glob('calibration_images\\\\*.jpg')\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001) # Corner refinement criteria\n",
    " \n",
    "for fname in images:\n",
    "    img = cv2.imread(fname, cv2.IMREAD_COLOR)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, pattern_size, None)\n",
    " \n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        obj_points.append(object_points)\n",
    " \n",
    "        corners2 = cv2.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "        img_points.append(corners2)\n",
    " \n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, pattern_size, corners2, ret)\n",
    "        resized = cv2.resize(img, (img.shape[1] // resize_factor, img.shape[0] // resize_factor))\n",
    "        cv2.imshow('img', resized)\n",
    "        cv2.waitKey(100)\n",
    " \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Calibrate the camera\n",
    "ret, K, dist, _, _ = cv2.calibrateCamera(obj_points, img_points, gray.shape[::-1], None, None)\n",
    "K_inv = np.linalg.inv(K)\n",
    "\n",
    "# Print intrinsic parameters\n",
    "print(\"Intrinsic Matrix :\\n\", K)\n",
    "print(\"Distortion coeffs :\\n\", dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Transformation from World to I0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_homogeneous(points):\n",
    "    ones = np.ones((points.shape[0], 1))\n",
    "    return np.hstack((points, ones))\n",
    "\n",
    "def to_cartesian(points):\n",
    "    return points[:, :-1] / points[:, -1][:, np.newaxis]\n",
    "\n",
    "def compute_H0(corners_W, corners_I0):\n",
    "    H_W_to_I0, _ = cv2.findHomography(corners_W, corners_I0)\n",
    "\n",
    "    \"\"\"\n",
    "    # Paper method : \"Markerless Tracking using Planar Structures in the Scene\" (page 5/9)\n",
    "    s = np.linalg.norm(H_W_to_I0[:,1]) / np.linalg.norm(H_W_to_I0[:,0])\n",
    "\n",
    "    D_inv = np.eye(3, dtype=np.float32)\n",
    "    D_inv[1, 1] = 1/s\n",
    "\n",
    "    H_W_to_I0 = H_W_to_I0 @ D_inv\n",
    "    \"\"\"\n",
    "\n",
    "    return H_W_to_I0\n",
    "\n",
    "def compute_T_normalized(H, K_inv):\n",
    "    R_t = K_inv @ H # [R|t] not normalized\n",
    "    r1 = R_t[:, 0]\n",
    "    r2 = R_t[:, 1]\n",
    "    \n",
    "    # Normalize the columns to ensure unit vectors\n",
    "    scale = np.linalg.norm(r1)\n",
    "    r1 = r1 / scale\n",
    "    r2 = r2 / scale\n",
    "    r3 = np.cross(r1, r2)\n",
    "    \n",
    "    R = np.column_stack([r1, r2, r3])\n",
    "    t = R_t[:, 2] / scale\n",
    "    \n",
    "    T = K @ np.column_stack([R, t]) # K[R|t] normalized\n",
    "    \n",
    "    return T, R, t\n",
    "\n",
    "def transform_points(points, T):\n",
    "    return points @ T.T # because : (T @ points.T).T = points @ T.T\n",
    "\n",
    "def project_points(points_W, T_W_to_I):\n",
    "    points_I = to_cartesian(transform_points(points_W, T_W_to_I)).astype(np.int32)\n",
    "    \n",
    "    return points_I.reshape(-1, 2)\n",
    "\n",
    "# Real-world coordinates of the 4 corners\n",
    "corners_W = np.array([[0, 0, 0], [0.185, 0, 0], [0.185, 0.185, 0], [0, 0.185, 0]])\n",
    "\n",
    "# Compute the transformations\n",
    "H_W_to_I0 = compute_H0(corners_W, corners_I0)\n",
    "T_W_to_I0, _, _ = compute_T_normalized(H_W_to_I0, K_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show axes (x, y, z) in I0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Axes in world coordinate system\n",
    "axes_W = np.array([[0, 0, 0, 1], [0.185/2, 0, 0, 1], [0, 0.185/2, 0, 1], [0, 0, -0.185/2, 1]])\n",
    "\n",
    "# Axes in camera coordinate system\n",
    "axes_I0 = project_points(axes_W, T_W_to_I0)\n",
    "origin, x_axis, y_axis, z_axis = axes_I0.astype(np.int32)\n",
    "\n",
    "# Draw axes\n",
    "I0_copy = np.copy(I0)\n",
    "cv2.arrowedLine(I0_copy, origin, x_axis, (255, 0, 0), 7)\n",
    "cv2.arrowedLine(I0_copy, origin, y_axis, (0, 255, 0), 7)\n",
    "cv2.arrowedLine(I0_copy, origin, z_axis, (0, 0, 255), 7)\n",
    "\n",
    "I0_resize = cv2.resize(I0_copy, (I0_copy.shape[1] // resize_factor, I0_copy.shape[0] // resize_factor))\n",
    "cv2.imshow(\"Axes\", I0_resize)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match keypoints between Ik and Ik+1 to compute transformation from world to Ik+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_I(I, corners):\n",
    "    corners = corners.astype(np.int32)\n",
    "    height, width = I.shape[:2]\n",
    "    mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    cv2.fillPoly(mask, [corners], 255)\n",
    "    masked_I = cv2.bitwise_and(I, I, mask=mask)\n",
    "\n",
    "    return masked_I\n",
    "\n",
    "masked_I0 = mask_I(I0, corners_I0)\n",
    "masked_I0_resize = copy_and_resize(masked_I0)\n",
    "\n",
    "cv2.imshow(\"Masked\", masked_I0_resize)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output videos\n",
    "fps = 30\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video_result = cv2.VideoWriter(\"result.mp4\", fourcc, fps, (I0.shape[1], I0.shape[0]))\n",
    "video_sift = cv2.VideoWriter(\"sift.mp4\", fourcc, fps, (I0.shape[1] * 2, I0.shape[0]))\n",
    "\n",
    "frame_number = 1\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Display frames during the process\n",
    "display_frames = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Frame : 1 / 119\n",
      "Current Frame : 2 / 119\n",
      "Current Frame : 3 / 119\n",
      "Current Frame : 4 / 119\n",
      "Current Frame : 5 / 119\n",
      "Current Frame : 6 / 119\n",
      "Current Frame : 7 / 119\n",
      "Current Frame : 8 / 119\n",
      "Current Frame : 9 / 119\n",
      "Current Frame : 10 / 119\n",
      "Current Frame : 11 / 119\n",
      "Current Frame : 12 / 119\n",
      "Current Frame : 13 / 119\n",
      "Current Frame : 14 / 119\n",
      "Current Frame : 15 / 119\n",
      "Current Frame : 16 / 119\n",
      "Current Frame : 17 / 119\n",
      "Current Frame : 18 / 119\n",
      "Current Frame : 19 / 119\n",
      "Current Frame : 20 / 119\n",
      "Current Frame : 21 / 119\n",
      "Current Frame : 22 / 119\n",
      "Current Frame : 23 / 119\n",
      "Current Frame : 24 / 119\n",
      "Current Frame : 25 / 119\n",
      "Current Frame : 26 / 119\n",
      "Current Frame : 27 / 119\n",
      "Current Frame : 28 / 119\n",
      "Current Frame : 29 / 119\n",
      "Current Frame : 30 / 119\n",
      "Current Frame : 31 / 119\n",
      "Current Frame : 32 / 119\n",
      "Current Frame : 33 / 119\n",
      "Current Frame : 34 / 119\n",
      "Current Frame : 35 / 119\n",
      "Current Frame : 36 / 119\n",
      "Current Frame : 37 / 119\n",
      "Current Frame : 38 / 119\n",
      "Current Frame : 39 / 119\n",
      "Current Frame : 40 / 119\n",
      "Current Frame : 41 / 119\n",
      "Current Frame : 42 / 119\n",
      "Current Frame : 43 / 119\n",
      "Current Frame : 44 / 119\n",
      "Current Frame : 45 / 119\n",
      "Current Frame : 46 / 119\n",
      "Current Frame : 47 / 119\n",
      "Current Frame : 48 / 119\n",
      "Current Frame : 49 / 119\n",
      "Current Frame : 50 / 119\n",
      "Current Frame : 51 / 119\n",
      "Current Frame : 52 / 119\n",
      "Current Frame : 53 / 119\n",
      "Current Frame : 54 / 119\n",
      "Current Frame : 55 / 119\n",
      "Current Frame : 56 / 119\n",
      "Current Frame : 57 / 119\n",
      "Current Frame : 58 / 119\n",
      "Current Frame : 59 / 119\n",
      "Current Frame : 60 / 119\n",
      "Current Frame : 61 / 119\n",
      "Current Frame : 62 / 119\n",
      "Current Frame : 63 / 119\n",
      "Current Frame : 64 / 119\n",
      "Current Frame : 65 / 119\n",
      "Current Frame : 66 / 119\n",
      "Current Frame : 67 / 119\n",
      "Current Frame : 68 / 119\n",
      "Current Frame : 69 / 119\n",
      "Current Frame : 70 / 119\n",
      "Current Frame : 71 / 119\n",
      "Current Frame : 72 / 119\n",
      "Current Frame : 73 / 119\n",
      "Current Frame : 74 / 119\n",
      "Current Frame : 75 / 119\n",
      "Current Frame : 76 / 119\n",
      "Current Frame : 77 / 119\n",
      "Current Frame : 78 / 119\n",
      "Current Frame : 79 / 119\n",
      "Current Frame : 80 / 119\n",
      "Current Frame : 81 / 119\n",
      "Current Frame : 82 / 119\n",
      "Current Frame : 83 / 119\n",
      "Current Frame : 84 / 119\n",
      "Current Frame : 85 / 119\n",
      "Current Frame : 86 / 119\n",
      "Current Frame : 87 / 119\n",
      "Current Frame : 88 / 119\n",
      "Current Frame : 89 / 119\n",
      "Current Frame : 90 / 119\n",
      "Current Frame : 91 / 119\n",
      "Current Frame : 92 / 119\n",
      "Current Frame : 93 / 119\n",
      "Current Frame : 94 / 119\n",
      "Current Frame : 95 / 119\n",
      "Current Frame : 96 / 119\n",
      "Current Frame : 97 / 119\n",
      "Current Frame : 98 / 119\n",
      "Current Frame : 99 / 119\n",
      "Current Frame : 100 / 119\n",
      "Current Frame : 101 / 119\n",
      "Current Frame : 102 / 119\n",
      "Current Frame : 103 / 119\n",
      "Current Frame : 104 / 119\n",
      "Current Frame : 105 / 119\n",
      "Current Frame : 106 / 119\n",
      "Current Frame : 107 / 119\n",
      "Current Frame : 108 / 119\n",
      "Current Frame : 109 / 119\n",
      "Current Frame : 110 / 119\n",
      "Current Frame : 111 / 119\n",
      "Current Frame : 112 / 119\n",
      "Current Frame : 113 / 119\n",
      "Current Frame : 114 / 119\n",
      "Current Frame : 115 / 119\n",
      "Current Frame : 116 / 119\n",
      "Current Frame : 117 / 119\n",
      "Current Frame : 118 / 119\n"
     ]
    }
   ],
   "source": [
    "rotations = []\n",
    "translations = []\n",
    "\n",
    "if display_frames:\n",
    "    cv2.namedWindow(\"Axes\")\n",
    "    cv2.namedWindow(\"Matches\")\n",
    "    waitkey = 1\n",
    "\n",
    "# When frame number = 0, the previous frame is I0\n",
    "Ik = masked_I0\n",
    "corners = corners_I0\n",
    "H_I0_to_Ik = np.eye(3)\n",
    "\n",
    "while True:\n",
    "    ret, Ik1 = cap.read()\n",
    "    Ik1 = cv2.rotate(Ik1, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    print(\"Current Frame :\", frame_number, \"/\", frame_count)\n",
    "\n",
    "    # Compute keypoints in Ik and Ik1\n",
    "    detector = cv2.SIFT_create()\n",
    "    kpk, desk = detector.detectAndCompute(Ik, None)\n",
    "    kpk1, desk1 = detector.detectAndCompute(Ik1, None)\n",
    "\n",
    "    # Match the keypoints\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2)\n",
    "    matches = bf.match(desk, desk1)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    if len(matches) < 4:\n",
    "        print(\"Not enough matches for homography\")\n",
    "        continue\n",
    "\n",
    "    # Points in image plane coordinates\n",
    "    x_Ik = np.array([kpk[m.queryIdx].pt for m in matches]).reshape(-1, 2)\n",
    "    x_Ik1 = np.array([kpk1[m.trainIdx].pt for m in matches]).reshape(-1, 2)\n",
    "\n",
    "    # Compute homography between Ik and Ik1\n",
    "    H_Ik_to_Ik1, RANSAC_mask = cv2.findHomography(x_Ik, x_Ik1, cv2.RANSAC, 3.0)\n",
    "    matches_inliers = [matches[i] for i in range(len(matches)) if RANSAC_mask[i] == 1]\n",
    "\n",
    "    # Compute homography between Ik and Ik1\n",
    "    H_I0_to_Ik1 = H_Ik_to_Ik1 @ H_I0_to_Ik\n",
    "\n",
    "    # Compute transformation between world and Ik1\n",
    "    H_W_to_Ik1 = H_I0_to_Ik1 @ H_W_to_I0\n",
    "    T_W_to_Ik1, R, t = compute_T_normalized(H_W_to_Ik1, K_inv)\n",
    "    rotations.append(R)\n",
    "    translations.append(t)\n",
    "\n",
    "    # Axes in camera coordinate system\n",
    "    axes_Ik1 = project_points(axes_W, T_W_to_Ik1)\n",
    "    origin, x_axis, y_axis, z_axis = axes_Ik1.astype(np.int32)\n",
    "\n",
    "    # Update corners, Ik and H_I0_to_Ik\n",
    "    corners = np.float32(corners).reshape(-1, 1, 2)\n",
    "    corners = cv2.perspectiveTransform(corners, H_Ik_to_Ik1)\n",
    "    Ik = mask_I(Ik1, corners)\n",
    "    H_I0_to_Ik = H_I0_to_Ik1\n",
    "\n",
    "    # Draw matches\n",
    "    I_matches = cv2.drawMatches(Ik, kpk, Ik1, kpk1, matches_inliers, None, matchColor=(0, 255, 0), singlePointColor=(255, 0, 0), flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    \n",
    "    # Draw polylines\n",
    "    cv2.polylines(Ik1, [corners.astype(np.int32)], isClosed=True, color=(0, 165, 255), thickness=3)\n",
    "\n",
    "    # Draw axes\n",
    "    cv2.arrowedLine(Ik1, origin, x_axis, (255, 0, 0), 7)\n",
    "    cv2.arrowedLine(Ik1, origin, y_axis, (0, 255, 0), 7)\n",
    "    cv2.arrowedLine(Ik1, origin, z_axis, (0, 0, 255), 7)\n",
    "\n",
    "    video_result.write(Ik1)\n",
    "    video_sift.write(I_matches)\n",
    "    frame_number += 1\n",
    "\n",
    "    if display_frames:\n",
    "        # Display matches\n",
    "        I_matches_resize = cv2.resize(I_matches, (I_matches.shape[1] // resize_factor, I_matches.shape[0] // resize_factor))\n",
    "        cv2.imshow(\"Matches\", I_matches_resize)\n",
    "\n",
    "        # Display axes\n",
    "        Ik1_resize = cv2.resize(Ik1, (Ik1.shape[1] // resize_factor, Ik1.shape[0] // resize_factor))\n",
    "        cv2.imshow(\"Axes\", Ik1_resize)\n",
    "\n",
    "        key = cv2.waitKey(waitkey) & 0xFF\n",
    "\n",
    "        if key == ord('p'):\n",
    "            waitkey = 1 if waitkey == 0 else 0\n",
    "\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    \n",
    "video_sift.release()\n",
    "video_result.release()\n",
    "\n",
    "if display_frames:\n",
    "    cv2.destroyAllWindows()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for R, t in zip(rotations, translations):\n",
    "    line = np.hstack((R.flatten(), t))\n",
    "    data.append(line)\n",
    "\n",
    "data = np.array(data)\n",
    "np.savetxt(\"poses.txt\", data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
